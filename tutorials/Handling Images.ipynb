{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Images\n",
    "\n",
    "In this notebook you will:\n",
    "\n",
    "* Load image data into a table and discover that that is not so nice to work with.\n",
    "* Load image data lazily using the ``.data()`` method.\n",
    "* Perform streaming computations on the lazily-loaded data.\n",
    "* Access multiple columns of data lazily using the ``.events()`` method.\n",
    "\n",
    "Recommended Prerequisites:\n",
    "\n",
    "* [Process Tabular Data with Pandas](./Process%20Tabular%20Data%20with%20Pandas.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs EPICS IOC(s) with simulated hardware in leiu of actual motors, detectors.\n",
    "!supervisor/start_supervisor.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/beamline_configuration.py\n",
    "I.kind = 'normal'  # We do not wanted the beam current to be the 'hinted' value in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array data in Theory\n",
    "\n",
    "We can read more than just scalar data using Bluesky.  For handling\n",
    "non-scalar data (such as from imaging detectors or MCAs) we do not\n",
    "directly store the data in the databroker, instead we store _pointer_\n",
    "to where the data is and how to access it.  This design allows us to buffer the user from such mundane details as what the filename and format of the underlying data is.  \n",
    "This is also motivated in part by performance concerns both at the database level, you do not want to put gigabytes of binary data into a database, and at the collection level, we do not want to put Bluesky between detectors and disk. \n",
    "\n",
    "In short, these _pointers_ allow *DataBroker* to do the file I/O work of opening and extracting data from disk and returns to you numpy arrays.  For more [details about how this works](https://nsls-ii.github.io/databroker/assets.html) see the DataBroker documentation.\n",
    "\n",
    "\n",
    "## Array data in practice\n",
    "\n",
    "Lets take a single frame of a low signal-to-noise detector to see how this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(mv(spot.exp, .005))  # low exposure time so we will get significant noise\n",
    "RE(mv(mtr_spotx, 0, mtr_spoty, 0))  # set position to dead center\n",
    "\n",
    "RE(count([spot, I], num=1))\n",
    "h_one = db[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at this with `table`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_one.table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a uid string in the column where we expect our image to be!  Taking a look at the `'spot_img'`'s entry in the descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_one.descriptors[0]['data_keys']['spot_img']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see that the expeted shape is `(480, 640)` and `'external'` key indicates that these strings are keys to trade to the *DataBroker* for the actual data. To ask\n",
    "*DataBroker* to fetch the image data from disk we can pass the optional kwarg `fill`\n",
    "to `table`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_one.table(fill=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_one.table(fill=True)['spot_img'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but it is embedded in a Pandas data frame.  The `Header` has the\n",
    "``data`` method which pulls out one column of the stream (and defaults to\n",
    "`fill=True`).\n",
    "\n",
    "The object returned by `h.data` is a *generator* which will lazily return\n",
    "one value at a time.  To grab just the first image we can use `next`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = next(h_one.data('spot_img'))\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im_artist = ax.imshow(im)\n",
    "fig.colorbar(im_artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have already been working with *generator* functions as under-the-hood the built in  *BlueSky* plans are all generators.  For more details on generators see [the BlueSky appendix](https://nsls-ii.github.io/bluesky/appendix.html) or google [\"James Powell generators youtube\"](https://www.google.com/search?q=james+powell+generators+youtube).\n",
    "\n",
    "If we know there is exactly 1 image we can unpack it like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, = h_one.data('spot_img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To play with generators a bit more, lets take some data with multiple frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(count([spot, I], num=5))\n",
    "h_few = db[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is more than one we can use `list`, `np.stack`, or\n",
    "Python's \"generalize unpacking\" to pull all of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_list = list(h_few.data('spot_img'))\n",
    "im_stack = np.stack(h_few.data('spot_img'))\n",
    "im1, *rest = h_few.data('spot_img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also iterate through all of them with a `for` loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, im in enumerate(h_few.data('spot_img')):\n",
    "    print(f'frame {j} has max {im.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has the nice feature that there is only ever 1 frame in memory at a time.  For these 5 small images, this is not a huge issue, but this technique can allow you to process data significantly bigger than your available memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a few minutes to play the the 4 ways to get all of the images out of the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a bunch of images to improve the statistics!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RE(count([spot, I], num=150))\n",
    "h_lots = db[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again use ``next`` to peek at the first image *without loading the rest of it*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = next(h_lots.data('spot_img'))\n",
    "fig, ax = plt.subplots()\n",
    "im_artist = ax.imshow(im)\n",
    "fig.colorbar(im_artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then grab the whole stack, average them to one image and\n",
    "display the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "im_stack = np.stack(h_lots.data('spot_img'))\n",
    "\n",
    "vmin = im_stack.min()\n",
    "vmax = im_stack.max()\n",
    "\n",
    "im1 = ax1.imshow(im_stack[0], vmin=vmin, vmax=vmax)\n",
    "im2 = ax2.imshow(im_stack.mean(axis=0), vmin=vmin, vmax=vmax)\n",
    "\n",
    "ax1.set_title('1 frame')\n",
    "ax2.set_title('mean of stack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy access over more than one column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data` can pull out any column.  If you want to access both the beam current and the image you could access them separately and use ``zip`` to loop over them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.zeros((480, 640))\n",
    "j = 0\n",
    "for cur, im in zip(h_lots.data('I'), h_lots.data('spot_img')):\n",
    "    out += im / cur  # cumulative sum of image pixel data\n",
    "    j += 1  # count total number of images\n",
    "\n",
    "out /= j  # i.e. convert the sum to a mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if you need to access more than one key, it may be better to\n",
    "use the *Event* documents directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.zeros((480, 640))\n",
    "j = 0\n",
    "for event in h_lots.events(fill=True):\n",
    "    im = event['data']['spot_img']\n",
    "    cur = event['data']['I']\n",
    "    out += im / cur  # cumulative sum of image pixel data\n",
    "    j += 1  # count total number of images\n",
    "\n",
    "out /= j  # i.e. convert the sum to a mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scanning with the spot detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(mv(spot.exp, 5))  # Set exposure time higher to get bettter signal-to-noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at how the spot changes as we scan the motors `mtr_spotx` and `mtr_spoty`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be explict about the source of the scan and the uid\n",
    "grid_uid, = RE(bp.grid_scan([spot, I], mtr_spotx, -100, 100, 5, mtr_spoty, -100, 100, 5, False))  \n",
    "h_grid = db[grid_uid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table and live-plot showed us how the total intensity changed as a function of position, but we can dig into the events and look at "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_arr = plt.subplots(5, 5)\n",
    "im_arts = []\n",
    "d_min = np.inf\n",
    "d_max = -np.inf\n",
    "for ax, event in zip(ax_arr.ravel(), h_grid.events(fill=True)):\n",
    "    data = event['data']\n",
    "    ax.axis('off')\n",
    "    im_arts.append(ax.imshow(data['spot_img']))\n",
    "    d_min = min(d_min, data['spot_img'].min())\n",
    "    d_max = max(d_max, data['spot_img'].max())\n",
    "    ax.set_title(f'({data[\"motor_spotx\"]}, {data[\"motor_spoty\"]})', size='xx-small', pad=2)\n",
    "\n",
    "# set the same color scale on all of the images\n",
    "for art in im_arts:\n",
    "    art.set_clim(d_min, d_max)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which shows us that the spot changes intensity and moves around.\n",
    "\n",
    "### Mapping the intensity\n",
    "\n",
    "Now lets map out the intensity a bit more systematically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RE(spiral_fermat([I, spot], mtr_spotx, mtr_spoty, 0, 0, 75, 75, 3, 1))\n",
    "h_spiral = db[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The live plot shows us a scatter of the x-y positions of the motor colored by the `'spot_roi'` which shows the overall drop off we expect as a function of position.  However, some of the structure in it maybe due to the variation in the beam current.  To investigate this lets make contour plots of the un-normalized and normalized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tricontour_helper(df, ax, title):\n",
    "    \"\"\"\n",
    "    Plot a filled triangular contour plot of unstructured (ungridded) data.\n",
    "    \"\"\"\n",
    "    ax.tricontour(df['x'], df['y'], df['color'], 10, linewidths=0.5, colors='k')\n",
    "    t = ax.tricontourf(df['x'], df['y'], df['color'], 10)\n",
    "    ax.set_title(title)\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fist, get a dataframe of the (x, y) positions and an (rough) proxy for the summed intensity in the peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for event in h_spiral.events(fill=True):\n",
    "    data = event['data']  # just to save typing below...\n",
    "    im = data['spot_img']\n",
    "\n",
    "    rows.append({'x': data['motor_spotx'],\n",
    "                 'y': data['motor_spoty'],\n",
    "                 'color': np.mean(im[im > 1000])})\n",
    "\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Netx, get a dataframe of the (x, y) positions and an (rough) proxy for the summed intensity in the peak normalized by the measured beam current."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for event in h_spiral.events(fill=True):\n",
    "    data = event['data']\n",
    "    im = data['spot_img']\n",
    "\n",
    "    rows.append({'x': data['motor_spotx'],\n",
    "                 'y': data['motor_spoty'],\n",
    "                 'color': np.mean(im[im > 1000]) / data['I']})\n",
    "\n",
    "df_normed = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "tricontour_helper(df, ax1, 'un-normalized')\n",
    "tricontour_helper(df_normed, ax2, 'normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
