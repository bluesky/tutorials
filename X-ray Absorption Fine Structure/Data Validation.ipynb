{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fe6de51-4764-4841-b037-7eba98af21c0",
   "metadata": {},
   "source": [
    "# XAS data validation by a simple machine learning model\n",
    "\n",
    "**Objective**: Train a computer to recognize when a measured spectrum looks like XAS data.\n",
    "\n",
    "At my beamline [BMM](https://www.bnl.gov/nsls2/beamlines/beamline.php?r=6-BM), we try to run 24 hours per day by relying upon robust instrumentation and well-tested automation. We have ways of lining up 10s of hours of data collection and letting the beamline run itself. From time to time, however, something goes wrong.  Maybe a detector has failed, maybe a sample has fallen off the sample holder, maybe the user told the automation to do the wrong thing.  Who knows?  Gremlins happen!\n",
    "\n",
    "What we want is a spimple sort of data evaluation.  My talk today is not about XAS data reduction ... nor anlaysis ... nor interpretation ....\n",
    "\n",
    "The problem I want to solve here is to flag a spectrum **as its measurement completes** as being either\n",
    "1. \"these data are probably reasonable\" or\n",
    "2. \"someone's attention is probably needed\"\n",
    "\n",
    "The basic observation is that this identification problem is fundementally the same at the famous Iris Classification Problem &ndash; which is the \"Hello World!\" of machine learning.\n",
    "\n",
    "## The Iris Classification Problem\n",
    "\n",
    "In this classic problem, we work with a data set of observations of the morphology of the flowers of three species of iris:\n",
    "\n",
    "![irises](./static/irises.png)\n",
    "[(image source)](https://data-flair.training/blogs/iris-flower-classification/)\n",
    "\n",
    "**Sepal**: One of the usually green leaflike structures composing the outermost part of a flower. Sepals often enclose and protect the bud and may remain after the fruit form\n",
    "\n",
    "**Petal**: One of the often brightly colored parts of a flower immediately surrounding the reproductive organs; a division of the corolla.\n",
    "\n",
    "Note that the shapes of the petals and sepals of these three species are different from one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aeb0d4-511c-4925-91d5-dd358e883b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import sklearn.datasets\n",
    "iris_set = sklearn.datasets.load_iris()\n",
    "\n",
    "i = pandas.DataFrame()\n",
    "i['sepal length'] = iris_set.data[:,0]\n",
    "i['sepal width']  = iris_set.data[:,1]\n",
    "i['petal length'] = iris_set.data[:,2]\n",
    "i['petal width']  = iris_set.data[:,3]\n",
    "i['target']       = iris_set.target\n",
    "i['species']      = iris_set.target_names[iris_set.target]\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d013600f-4c1f-4f01-9ee1-0a3600025f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "formatter = plt.FuncFormatter(lambda i, *args: iris_set.target_names[int(i)])\n",
    "\n",
    "plt.scatter(i['petal length'], i['petal width'], c=i['target'])\n",
    "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "plt.xlabel('petal length')\n",
    "plt.ylabel('petal width')\n",
    "plt.title(\"Classification: Petal measurements\")\n",
    "## plotting credit: http://stephanie-w.github.io/brainscribble/classification-algorithms-on-iris-dataset.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3d43f5-08c4-4d5a-84ed-8b75a025060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(i['sepal length'], i['sepal width'], c=i['target'])\n",
    "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('sepal width')\n",
    "plt.title(\"Classification: Sepal measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cba3eaf-f130-43b8-bca3-c8ef4454073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(i['petal width'], i['sepal length'], c=i['target'])\n",
    "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "plt.xlabel('petal width')\n",
    "plt.ylabel('sepal length')\n",
    "plt.title(\"Classification: PW vs. SL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b6abe-26de-4c66-9c0f-4d4ddc07eac8",
   "metadata": {},
   "source": [
    "Thanks to nicely contrasting colors and the human brain's penchant for finding patterns, you can look at these two representations of the iris dataset and see that the species cluster according to the dimensions of their sepals and petals.\n",
    "\n",
    "Remember that these pictures are 2-dimensional samplings of a 4-dimensional space of sepal and petal measurements.  The clustering in this data set is in a 4D manifold.\n",
    "\n",
    "Now, imagine picking a new iris of unknown species with the intent of identifying it.  You might measure the length and width of its sepal and petal and drop the new measurement onto that 4D manifold.  The idea is to determine its species on the basis of the nearby, tagged data points.\n",
    "\n",
    "To implement this in numbers (as opposed to human perception), we'll use an algorithm called \"K Nearest Neighbors\" (KNN).  To explain KNN, I'll simply plagiarize Wikipedia:\n",
    "\n",
    "![KNN](./static/KnnClassification.svg)\n",
    "[(image source)](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)\n",
    "\n",
    "Quoth Wikipedia: \"The test sample (green dot) should be classified either to blue squares or to red triangles. If k = 3 (solid line circle) it is assigned to the red triangles because there are 2 triangles and only 1 square inside the inner circle. If k = 5 (dashed line circle) it is assigned to the blue squares (3 squares vs. 2 triangles inside the outer circle).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f745fa2-3224-4022-998e-db3016c51635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(i[['sepal length', 'sepal width', 'petal length', 'petal width']], i['target'], random_state=0)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c292d0-2a16-4d81-bc21-1a8904cfbbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46390ce0-3bcd-44e1-903f-8043e7bcdb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29592546-5e98-404e-9798-dc2829725362",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4908155e-1e90-4d47-8977-96a2e4462be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=5.)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c63361-ca97-4d95-9b33-dcb46f05256b",
   "metadata": {},
   "source": [
    "Here is the documentation from scikit-learn on the iris dataset:\n",
    "https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html and for more information, follow the other links cited above.\n",
    "\n",
    "So ... how does a fun botany problem related to XAS?\n",
    "\n",
    "## Classifying XAS spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf84001-ca16-41a4-8d52-3974c3bf39c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import os\n",
    "notebook_path = os.path.dirname(os.path.abspath(\"Data Validation.ipynb\"))\n",
    "\n",
    "def fetch_xas_scan(uid):\n",
    "    fname = uid + '.csv'\n",
    "    data = pandas.read_csv(os.path.join(notebook_path, \"data\", \"ML_corpus\", fname))\n",
    "    data.plot(\"dcm_energy\", \"xmu\", xlabel='Energy (eV)', ylabel='$\\mu$(E)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587dfb4e-6ddd-4548-9b8e-f1811a2f2f08",
   "metadata": {},
   "source": [
    "Most of the data from this presentation is taken from a weekend in 2021 -- during time-of-covid, at a time when all the experiments at BMM were mail-in, and during a time when I was monitoring the beamline from home.  Being a nice Saturday, I set many hours of data collection running and then walked away.\n",
    "\n",
    "That weekend, I was working on ceramic samples from colleagues at the University of Sheffield. We were measuring XAS on the iron, cerium, and titanium edges.\n",
    "\n",
    "Here are some examples of reasonable data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f0ebf4-41ea-4af3-906f-d3c5a3b49d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## a good one (Fe)\n",
    "fetch_xas_scan('4de69926')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9c2bd4-f1a8-438b-bf02-e50a2446affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## a good one (Ce)\n",
    "fetch_xas_scan('4f3c2372')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2378b33e-b2d1-40ba-bbcf-613c09454b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a good one (Ti)\n",
    "fetch_xas_scan('6916040c')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d667f0-118b-4bee-be93-37d1b4bff202",
   "metadata": {},
   "source": [
    "At some point during the weekend, something ... **BAD** ... happened. In truth, I don't quite remember what the problem was -- my lossy memory tells me that something weird happened with the fluorescence detector.  In any case, for something like 10 hours, garbage was measured before I finally noticed.\n",
    "\n",
    "Here are a couple of examples of **BAD** data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc75a3c-2553-40fa-aeb4-f7bc2154b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "## a bad one\n",
    "fetch_xas_scan('88b9e311')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b56634-1ca7-42b6-a29d-8d6a5fbd06b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## another bad one\n",
    "fetch_xas_scan('64887ce3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afefd0-9043-439f-af20-958b1f36d629",
   "metadata": {},
   "source": [
    "### Preparing the training data\n",
    "\n",
    "This is a \"supervised learning\" problem.  That means that a human (me!) goes through the training data and tags each spectrum as *good* or *bad*.  \n",
    "\n",
    "The data can be found in the `data/ML_corpus folder`. Each scan has been slurped from DataBroker, lightly reduced, then exported as a CSV file with columns for energy and $\\mu$(E).  In the code block above, we used the `pandas.read_csv()` method to import the $\\mu$(E) data for plotting.\n",
    "\n",
    "I wrote a [simple shell script](./data/ML_corpus/tag.sh) that steps through each spectrum in the training set, displays a plot of each spectrum, and prompts for a score for each spectrum.\n",
    "\n",
    "**\"good data**: score = 1 &ndash; a spectrum that looked to my human eye like it stepped up then wiggled.\n",
    "\n",
    "**\"bad data\"**: score = 0 &ndash; a spectrum that looked to my human eye like it **did not** step up then wiggle.\n",
    "\n",
    "(Side note: human tagging of a data set is tedious and error prone.  An ideal model would be tolerant of errors in the training set.)\n",
    "\n",
    "The scoring was saved as [a JSON file](./data/ML_corpus/tags.json). Let's see what the first seven entries in that JSON file look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8716ba20-ac77-4104-88bb-7d238d41be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, itertools\n",
    "with open(\"./data/ML_corpus/tags.json\") as infile:\n",
    "    tags = json.load(infile)\n",
    "dict(itertools.islice(tags.items(),  1, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cbabc9-4f45-4778-a23f-75a521528ee7",
   "metadata": {},
   "source": [
    "Let's do a spot check on of the good ones (`04fed2c6.csv`) and on one of the bad ones (`0920716b.csv`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae8f53-91fa-4dbc-bade-dcc1235585a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_xas_scan('04fed2c6') # this one is tagged as \"good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac02136-ce79-4100-9a77-1414e301a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_xas_scan('0920716b') # this one is tagged as \"bad\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2016c733-5a84-4465-9779-bd49064a6274",
   "metadata": {},
   "source": [
    "Great!  Now we can start constructing our training set.\n",
    "\n",
    "First thing: we need to \"rationalize\" the data. The trainer expects all the data to be the same size -- for example, each observation of an iris had 4 data points (width and length of sepal and petal).  Similarly, the XAS spectra in our training set need to have the same number of energy points. Because differnt scans mght have different numbers of energy point, we will interpolate all the data onto a 401-point grid which is evenly spaced across the energy range of the original XAS scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd56d3b1-5bd6-4a1f-aaa8-c9fdde514cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def rationalize_mu(en, mu):\n",
    "    '''Return energy and mu as a dataframe with data interpolated onto \n",
    "    a \"rationalized\" grid of equally spaced points.  GRIDSIZE = 401\n",
    "    '''\n",
    "    GRIDSIZE = 401\n",
    "    ee=list(numpy.arange(en[0], en.iloc[-1], (en.iloc[-1]-en[0])/GRIDSIZE))\n",
    "    mm=numpy.interp(ee, en, mu)\n",
    "    if len(ee) > GRIDSIZE:\n",
    "        ee = ee[:-1]\n",
    "        mm = mm[:-1]\n",
    "    df = pandas.DataFrame()\n",
    "    df['dcm_energy'] = ee\n",
    "    df['xmu'] = mm\n",
    "    return(df)\n",
    "\n",
    "def plot_rationalized_data(data, rat):\n",
    "    '''Make a quick-n-dirty of the original data and the data interpolated onto a 401-point grid.\n",
    "    '''\n",
    "    data.plot(\"dcm_energy\", \"xmu\", xlabel='Energy (eV)', ylabel='$\\mu$(E)', label='original')\n",
    "    ax = plt.gca()\n",
    "    rat.plot(\"dcm_energy\", \"xmu\", xlabel='Energy (eV)', ylabel='$\\mu$(E)', label='rationalized', ax=ax)\n",
    "    \n",
    "\n",
    "data = pandas.read_csv(os.path.join(notebook_path, \"data\", \"ML_corpus\", '04fed2c6.csv'))\n",
    "data_rational = rationalize_mu(data['dcm_energy'], data['xmu'])\n",
    "plot_rationalized_data(data, data_rational)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e09656-10b5-4505-916d-939f5f6431d2",
   "metadata": {},
   "source": [
    "And here's a bad one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84851752-f6fa-4c94-ae96-5b389f8fe182",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv(os.path.join(notebook_path, \"data\", \"ML_corpus\", '0920716b.csv'))\n",
    "data_rational = rationalize_mu(data['dcm_energy'], data['xmu'])\n",
    "plot_rationalized_data(data, data_rational)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15355b19-f82f-46b7-ad22-b27255f9f945",
   "metadata": {},
   "source": [
    "Almost ready!  Now, we need to import the entire tagged learning corpus into a form ready to be consumed by the sklearn classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c48054-0513-4d0d-a8a4-42de8c854fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [x for x in os.listdir(os.path.join(notebook_path, \"data\", \"ML_corpus\")) if x.endswith('csv')]\n",
    "corpus = []\n",
    "scores = []\n",
    "for f in csv_files:\n",
    "    data = pandas.read_csv(os.path.join(notebook_path, \"data\", \"ML_corpus\", f))\n",
    "    data_rational = rationalize_mu(data['dcm_energy'], data['xmu'])\n",
    "    corpus.append(list(data_rational['xmu']))\n",
    "    scores.append(tags[f])\n",
    "    \n",
    "clf=KNeighborsClassifier(n_neighbors=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(corpus, scores, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4856e30d-8ce4-43f1-8c56-00db40df53ec",
   "metadata": {},
   "source": [
    "94% success on the training set!  Not bad for an extremely naive approach to the problem.  Let's see if we can't improve upon this without having to do too much more work.\n",
    "\n",
    "[SciKit Learn](https://scikit-learn.org/stable/index.html) comes with a rather enormous number of\n",
    "[supervised learning models](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning). Let's try another one!\n",
    "\n",
    "(Give a two sentence explanation of a random forest classifier.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f3ca2f-04f5-481e-bfae-b4c68471f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bb6679-a090-42d9-be54-83a09ffb2051",
   "metadata": {},
   "source": [
    "98.5%!  Woot!  Now we're gettin' somewhere!\n",
    "\n",
    "We are already starting to push up against my dilettante's knwoledge of machine learning. A more informed choice of classifier can be made (and was, by Phil, in the paper a group of us here at NSLS-II just got published), but let's plow ahead using our random forest.\n",
    "\n",
    "To get a sense of how this works, let's look at the first item in test portion of the training set.  Let's see how I tagged it, what it looks like when plotted, and how it evaluates using the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb700fc5-9821-4df3-bbd6-d58891901d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97108e17-31a7-4518-b0ec-2d58843d9fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a39faf-9172-4ba7-ab70-4ca247425253",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([X_test[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d48b8c-18c2-4acc-8047-d585369c70a8",
   "metadata": {},
   "source": [
    "The predict function returns a 1 or a 0 on the basis of its evaluation of the supplied test data.  In this case, the model and I agree about these data. Yay!\n",
    "\n",
    "Let's try it on a spectrum not in the training set! Here's an Fe edge spectrum measured on a completely different sample from a completely different area of science which was measured over a year later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b92db-6a0e-4776-bbeb-1a86b3d09bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown = pandas.read_csv(os.path.join(notebook_path, \"data\", \"ML_unknown\", \"unknown_Fe.csv\"))\n",
    "unknown_rational = rationalize_mu(unknown['dcm_energy'], unknown['xmu'])\n",
    "plot_rationalized_data(unknown, unknown_rational)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7948fa-3c8d-468e-8cf4-651332fd45cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([list(unknown_rational['xmu'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df09490-c9a3-41db-a394-547ca343bed3",
   "metadata": {},
   "source": [
    "Splendid!  A visual inspection tells us that the new spectrum looks like XAS data and our model agrees!\n",
    "\n",
    "## Using our model\n",
    "\n",
    "Once our model is created, we can follow sklearn's hints about [model persistence](https://scikit-learn.org/stable/modules/model_persistence.html).  The model gets serialized to a [joblib](https://joblib.readthedocs.io/en/latest/persistence.html) file.  The file containing the model serialization is part of the [bluesky profile at BMM](https://github.com/NSLS-II-BMM/profile_collection).  Thus this machine learning model is always available and ready to be integrated into our operations.\n",
    "\n",
    "In practice, we compare *every* spectrum measured against our model.  The plan we use to measure an XAS spectrum includes a loop over the numbr of repetitions reqeusted by the user.  As part of that loop, the data that just finished are rationalized as discussed above and scored by the model.\n",
    "\n",
    "At BMM, we use Slack to provide feedback to users and staff during the experiment.  In the screenshot below, you can see the result of the data evaluation for each of two repetitions on that sample.  At the end of the two repetitions, the data are merged and lightly process, then a picture of the data are posted to Slack.\n",
    "\n",
    "![Slack+ML](./static/slack+ml.png)\n",
    "\n",
    "In this way, user and staff are given a hint about whether the experiment is progressing generally well or not.\n",
    "\n",
    "## Improving the model\n",
    "\n",
    "In practice, the model developed in this tutorial is not strong enough for general use.  Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c024cd-1183-4cae-80df-dd50a5bcb4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "failure = pandas.read_csv(os.path.join(notebook_path, \"data\", \"ML_unknown\", \"unknown_Zr.csv\"))\n",
    "failure_rational = rationalize_mu(failure['dcm_energy'], failure['xmu'])\n",
    "plot_rationalized_data(failure, failure_rational)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c9ae2-046a-4ecd-966a-75c90604923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([list(failure_rational['xmu'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d54aa5-8c1e-4e1a-9846-9a71453fa1df",
   "metadata": {},
   "source": [
    "Whomp! Whomp!\n",
    "\n",
    "Those Zr edge data are obviously excellent data, but the model in its current state does not recognize that.\n",
    "\n",
    "Over time, I have tagged more data and added them to the model.  The model in use at BMM is still not perfect.\n",
    "\n",
    "Reliablility in the high 90s still means that every day, a user will ask me \"Why did the data evaluation fail? What's wrong with my data?\"  Sigh....\n",
    "\n",
    "The actual implementation of this machine learning model at BMM is contained in [this file](https://github.com/NSLS-II-BMM/profile_collection/blob/master/startup/BMM/ml.py) from BMM's profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b10056-a2b3-4601-b9b6-bef569f64eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
